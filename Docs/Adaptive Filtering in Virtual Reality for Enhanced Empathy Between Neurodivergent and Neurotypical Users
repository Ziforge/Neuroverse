\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{listings}
\geometry{margin=1in}

\title{Adaptive Filtering in Virtual Reality for Enhanced Empathy Between Neurodivergent and Neurotypical Users}
\author{[Your Name]}
\date{March 2025}

\begin{document}

\maketitle

\begin{abstract}
This research investigates the development and implementation of adaptive sensory filtering within virtual reality (VR) environments to promote mutual understanding between neurotypical and neurodivergent individuals. By leveraging real-time behavioral tracking, perceptual models, and machine learning (ML), the system adjusts the sensory environment to suit user profiles derived from both developmental conditions (e.g., Autism Spectrum Condition, ADHD) and severe mental illnesses (e.g., bipolar disorder, schizophrenia). This paper presents a detailed theoretical foundation, technical architecture, machine learning strategy, platform integration with the Meta Quest 3, and a proposed experimental methodology suitable for a postgraduate research project in human-computer interaction (HCI), neuropsychology, or immersive technology.
\end{abstract}

\section{1. Introduction}
The growing recognition of neurodiversity in both clinical psychology and inclusive design highlights a pressing need to create shared spaces where individuals of differing perceptual and cognitive styles can engage meaningfully. Neurodivergent individuals—including those with Autism Spectrum Condition (ASC), Attention Deficit Hyperactivity Disorder (ADHD), and severe mental illness (SMI) such as bipolar disorder or schizophrenia—often experience the world through enhanced or dysregulated sensory systems. Traditional environments fail to accommodate these differences, resulting in exclusion or psychological stress.

Virtual reality (VR) and augmented reality (AR) represent a paradigm shift in experiential technology, offering dynamic environments where sensory parameters can be finely tuned, personalized, and adapted in real time. These qualities make VR a powerful medium for empathy-building and co-regulated interaction. The proposed system leverages adaptive filtering, behavioral data tracking, and machine learning to create an inclusive VR experience that responds to individual sensory needs while promoting a mutual awareness between users of different neurotypes.

\section{2. Literature Review}

\subsection{2.1 Sensory Modulation and Neurodivergence}
Sensory processing differences are a hallmark of neurodivergence. Dunn's Sensory Processing Framework \cite{dunn1997} outlines four patterns—Sensory Seeking, Sensory Avoiding, Sensory Sensitivity, and Low Registration—each of which characterizes a different way individuals interact with sensory stimuli. Individuals with ASC, for instance, often fall into the Sensory Sensitivity or Avoiding categories, making them more prone to overstimulation in typical environments. Conversely, those with ADHD may exhibit Sensory Seeking behavior, craving high levels of input to maintain attention.

\subsection{2.2 Sensory Dysregulation in Severe Mental Illness}
Severe mental illness (SMI), including schizophrenia and bipolar disorder, also manifests in altered sensory and perceptual processing. Schizophrenia has been linked to sensory gating deficits, where irrelevant stimuli are not filtered out effectively \cite{javitt2009}. This leads to perceptual flooding, hallucinations, and impaired attention. Bipolar disorder, meanwhile, can result in cyclical modulation of sensory thresholds, where manic phases increase reactivity to light and sound, and depressive phases reduce sensory responsiveness \cite{phillips2008}. These fluctuations suggest a need for real-time adaptive environments that can respond to changes in user state.

\subsection{2.3 Predictive Coding in Neurodivergence}
Predictive coding theory explains perception as the integration of top-down predictions and bottom-up sensory input. Van de Cruys et al. \cite{van2014} propose that individuals with ASC struggle with prediction attenuation, leading to an over-weighting of raw sensory input and increased anxiety in uncertain environments. Friston's dysconnection hypothesis \cite{friston2016} extends this to schizophrenia, positing that disrupted neural connectivity leads to misattribution of internally generated signals as external stimuli. These models support the use of adaptive sensory filters that dynamically rebalance the prediction-error weighting by modulating stimulus intensity and predictability.

\subsection{2.4 Polyvagal Theory and Safety Perception}
Polyvagal Theory \cite{porges2011} provides a physiological framework linking sensory input with autonomic nervous system states. Safe, predictable environments foster parasympathetic activation, promoting social engagement and learning. Conversely, environments that violate sensory expectations can trigger sympathetic responses, leading to withdrawal or defensive behavior. Adaptive VR systems can act as modulating agents that nudge users toward physiological safety, making them more receptive to social interaction and co-regulation.

\subsection{2.5 Perceptual Design Standards}
The FORCE Technology Sound Wheel \cite{force} categorizes audio perception using terms like "muffled," "sharp," "pleasant," or "aggressive," which map well onto human experience. ISO 9241-210 supports the use of perceptual affordances in interface design, emphasizing clarity, simplicity, and accessibility. These standards inform our use of user-facing terms and filtering controls in the VR interface.

\section{3. Research Questions}
\begin{enumerate}[label=RQ\arabic*.]
  \item Can adaptive sensory filtering based on passive input improve perceived comfort and presence in neurodivergent users?
  \item Does sensory blending promote empathy between users of differing neurotypes in shared VR environments?
  \item How accurately can machine learning models infer sensory preferences from behavioral features alone?
\end{enumerate}

\section{4. Methodology}

\subsection{4.1 Research Design}
This study follows a mixed-methods, within-subjects experimental design. Participants will engage in two distinct VR experiences: one with a static environment and the other with adaptive sensory filtering and profile blending. Pre- and post-session assessments will measure emotional, cognitive, and sensory engagement.

\subsection{4.2 Participants}
A total of 30 participants will be recruited, segmented into three equal groups:
\begin{itemize}
  \item Neurotypical individuals (n=10)
  \item Individuals with neurodevelopmental conditions such as ASC and ADHD (n=10)
  \item Individuals with severe mental illness (e.g., bipolar disorder, schizophrenia) (n=10)
\end{itemize}
Screening will include DSM-5 self-report checklists and the Sensory Profile 2. All participants will give informed consent.

To expand the reach and diversity of the participant base, recruitment will also be supported through an online platform. A project-specific website will host detailed study information, eligibility criteria, and consent forms, enabling remote pre-screening and registration. This digital outreach strategy aims to increase inclusivity, allowing individuals from a wider geographic and neurocognitive spectrum to participate.

\subsection{4.3 Equipment and Platform}
Experiments will be conducted using the Meta Quest 3 VR headset, chosen for its hand tracking, spatial mapping, and passthrough capabilities. Unity will be used for development, with C\# for scripting, and ML.NET or TensorFlow Lite for real-time inference.

\subsection{4.4 Procedure}
Each session includes:
\begin{enumerate}
  \item Calibration phase ($\leq$ 60 seconds): Users interact with multi-sensory zones
  \item Static condition: Users complete a cooperative task in a fixed VR space
  \item Adaptive condition: Same task but with ML-driven sensory adaptation and blending
  \item Post-test questionnaires and debrief
\end{enumerate}

\subsection{4.5 Data Collection and Protection}
\begin{itemize}
  \item Quantitative: NASA-TLX, SAM, Likert scales, task completion metrics
  \item Qualitative: Open-ended responses, interview recordings
  \item Behavioral: Gaze fixation, motion speed, interaction frequency
  \item \textbf{Anonymization:} All data will be anonymized before analysis using participant codes. No identifying information will be stored with behavioral or ML inference data.
  \item \textbf{GDPR Compliance:} Data will be stored securely in encrypted, GDPR-compliant storage systems. Participants will be able to access or request deletion of their data at any time.
\end{itemize}

\subsection{4.6 Open Source and GitHub Hosting}
To promote transparency, reproducibility, and community contribution, all non-sensitive project assets will be hosted on GitHub. This includes:
\begin{itemize}
  \item LaTeX documentation
  \item Pseudocode and Unity C\# scripts
  \item System architecture diagrams (including corrected versions)
  \item Anonymized data samples and evaluation tools
  \item Instructions for deployment and contribution
\end{itemize}
The repository will be publicly available under an open-source license (e.g., MIT or CC BY-NC 4.0) and will include contributor guidelines and README documentation for external collaborators.

\section{5. System Design}

\subsection{5.1 Architecture Overview}
The system includes five modular components:
\begin{itemize}
  \item SensorInputCollector
  \item CalibrationManager
  \item SensoryLearner (ML)
  \item FilterEngine
  \item BlendingManager
\end{itemize}
These modules communicate via Unity's update cycle and handle both user-specific and shared sensory logic.

\subsection{5.2 SensoryProfile Data Model}
\begin{verbatim}
class SensoryProfile {
    float sight;
    float sound;
    float touch;
    float motion;
    float proprioception;
}
\end{verbatim}

\subsection{5.3 User Flow}
\begin{enumerate}
  \item Initialization
  \item Calibration via micro-interaction scenes
  \item ML profile inference
  \item Environment adaptation begins
  \item Shared user blending if proximity threshold is crossed
  \item Experience concludes and resets for next session
\end{enumerate}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.85\textwidth]{corrected_vr_user_flow_diagram.png}
\caption{User flow diagram for the adaptive VR experience, from calibration to profile blending and debriefing.}
\label{fig:userflow}
\end{figure}

\section{6. Adaptive Filtering with Machine Learning}

\subsection{6.1 ML Model Type}
A decision tree or shallow neural net is trained offline and embedded using ML.NET (for C\#) or TensorFlow Lite (Unity Barracuda). 

\subsection{6.2 Feature Extraction}
\begin{itemize}
  \item Head movement speed
  \item Gaze dwell duration
  \item Interaction latency
  \item Teleportation frequency
\end{itemize}

\subsection{6.3 Inference Pipeline}
\begin{verbatim}
def predictProfile(sensorInput):
    features = extractFeatures(sensorInput)
    return model.predict(features)
\end{verbatim}

\subsection{6.4 Real-Time Adaptation}
Unity's AudioMixer, shader parameters, and animation controllers are modified via the FilterEngine. Adjustments are smoothed using exponential moving averages.

\subsection{6.5 Blending Logic}
When proximity is detected between users, profiles are interpolated:
\begin{verbatim}
blended = lerp(userA.profile, userB.profile, proximityFactor)
\end{verbatim}

\subsection{6.6 Safety and Transparency}
Users can pause, review, or reset adaptation through a simple UI. All adaptations are logged for post-session analysis and ethical transparency. Data logs are anonymized to comply with GDPR, and no real-time identifying information is processed or stored by the ML engine.



\section{7. Ethical Considerations}

Ethical considerations are central to the development and evaluation of adaptive sensory systems, particularly when working with neurodivergent and SMI populations. Key ethical protocols include:

\begin{itemize}
  \item \textbf{Informed Consent:} All participants must be briefed on adaptive features, data collection methods, and their right to withdraw without consequence.
  \item \textbf{Data Privacy:} Behavioral data is anonymized, encrypted, and stored in accordance with GDPR and institutional ethics board standards.
  \item \textbf{Real-Time Control:} Users can override, pause, or adjust adaptive filtering at any time to maintain agency.
  \item \textbf{Clinical Safeguards:} For SMI participants, a mental health professional will be available during trials to intervene if distress arises.
  \item \textbf{Debriefing and Feedback:} Post-trial interviews will be conducted to gather qualitative insights and identify adverse experiences.
\end{itemize}

\section{8. Anticipated Outcomes}

We anticipate the following outcomes based on prior research and theoretical models:

\begin{itemize}
  \item Users in the adaptive condition will report lower sensory discomfort and higher task engagement.
  \item Neurodivergent users will exhibit more stable interaction patterns and improved co-regulation when environments align with their inferred sensory profiles.
  \item Shared VR sessions with sensory blending will enhance subjective empathy scores, indicating mutual understanding.
  \item Machine learning models will successfully infer sensory profiles with >75\% accuracy using passive features alone.
\end{itemize}

These outcomes would support broader adoption of neuroadaptive systems in education, therapy, and accessibility design.

\section{9. Conclusion}

This research integrates cognitive science, machine learning, and immersive technology to propose a scalable framework for adaptive sensory filtering in virtual reality. Targeted at bridging the experiential gap between neurodivergent and neurotypical individuals, the system emphasizes transparency, personal agency, and inclusivity. By centering user comfort and co-regulation, the platform contributes to a more empathetic and accessible future for VR.

\begin{thebibliography}{9}
\bibitem{dunn1997} Dunn, W. (1997). The impact of sensory processing abilities on the daily lives of young children and their families. \textit{Infants \& Young Children}, 9(4), 23–35.

\bibitem{van2014} Van de Cruys, S., et al. (2014). Precise minds in uncertain worlds: Predictive coding in autism. \textit{Psychological Review}, 121(4), 649–675.

\bibitem{porges2011} Porges, S. W. (2011). \textit{The polyvagal theory: Neurophysiological foundations of emotions, attachment, communication, and self-regulation}. Norton.

\bibitem{javitt2009} Javitt, D. C., \& Freedman, R. (2009). Sensory processing dysfunction in schizophrenia. \textit{American Journal of Psychiatry}, 167(8), 817–828.

\bibitem{phillips2008} Phillips, M. L., \& Swartz, H. A. (2008). Neuroimaging studies of bipolar disorder. \textit{American Journal of Psychiatry}, 165(7), 830–843.

\bibitem{friston2016} Friston, K. (2016). The dysconnection hypothesis. \textit{Schizophrenia Research}, 176(2-3), 83–94.

\bibitem{force} FORCE Technology. (2020). \textit{Sound Wheel}. Retrieved from: \url{https://www.forcetechnology.com/en/services/product-sound/what-is-good-sound/the-sound-wheel}
\end{thebibliography}

\end{document}

